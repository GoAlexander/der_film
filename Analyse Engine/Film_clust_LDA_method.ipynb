{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "jewish        gets          local         teacher       middle        \n",
      "men           weed          bride         army          turn          \n",
      "english       union         assassinate   singer        puts          \n",
      "fortune       growers       college       zubrowka      make          \n",
      "grande        indulgent     trouble       firing        brother       \n",
      "sound         self          star          flesh         earth         \n",
      "flesh         boyhood       obstacles     flees         century       \n",
      "flees         tutsi         surprise      flee          self          \n",
      "flee          firepower     maker         flame         conscious     \n",
      "flame         oskar         investigator  firepower     awakening     \n",
      "\n",
      "\n",
      "topic 5       topic 6       topic 7       topic 8       topic 9       \n",
      "--------      --------      --------      --------      --------      \n",
      "dead          brutal        band          father        hotel         \n",
      "king          violent       heiress       vietnam       loss          \n",
      "musician      aging         lines         way           merchant      \n",
      "media         russian       wyoming       space         lundegaard    \n",
      "colonel       prohibition   hogwarts      japanese      finally       \n",
      "outlaw        era           morocco       travel        final         \n",
      "futuristic    rights        patriarch     terror        finch         \n",
      "surviving     woody         medieval      handedly      finding       \n",
      "ensure        unable        firepower     single        finds         \n",
      "white         flees         finds         following     flower        \n",
      "\n",
      "\n",
      "topic 10      topic 11      topic 12      topic 13      topic 14      \n",
      "--------      --------      --------      --------      --------      \n",
      "journey       earth         team          search        years         \n",
      "mob           underestimateshitler        forced        plans         \n",
      "falls         stranger      enemy         realize       imprisoned    \n",
      "couple        infiltrating  realities     jeff          universe      \n",
      "gandalf       zubrowka      boxing        pennsylvania  prostitute    \n",
      "germans       flees         wealthy       running       friendship    \n",
      "rabbit        flee          high          dreams        private       \n",
      "crew          flame         impacts       basis         desperate     \n",
      "finally       firing        arouses       colony        amadeus       \n",
      "finch         finds         mixture       voldemort     duality       \n",
      "\n",
      "\n",
      "topic 15      topic 16      topic 17      topic 18      topic 19      \n",
      "--------      --------      --------      --------      --------      \n",
      "family        child         depression    american      government    \n",
      "fight         murderer      prevent       boxer         soldier       \n",
      "school        sauron        leaders       decides       held          \n",
      "wrong         mining        era           prospector    based         \n",
      "celine        afflictions   station       thirty        sensitivity   \n",
      "avengers      waifish       lifeform      receive       northup       \n",
      "stepdaughter  television    troubles      jewelers      salvage       \n",
      "expands       sleazy        thought       maids         inspires      \n",
      "deal          finds         origins       americans     merely        \n",
      "flesh         finding       patients      aragorn       bicycle       \n",
      "\n",
      "\n",
      "========= First cluster\n",
      "\n",
      "Aliens\n",
      "The HuntRockyMonsters, Inc.\n",
      "Howl's Moving Castle\n",
      "On the Waterfront\n",
      "Lock, Stock and Two Smoking Barrels\n",
      "\n",
      "========= Second cluster\n",
      "\n",
      "Braveheart\n",
      "Rashomon\n",
      "Rebecca\n",
      "Apocalypse Now\n",
      "Inglourious Basterds\n",
      "The Terminator\n",
      "Apocalypse Now\n",
      "Three Billboards Outside Ebbing, Missouri\n",
      "Spotlight\n",
      "Jaws\n",
      "Rashomon\n",
      "Like Stars on Earth\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import requests\n",
    "import eventlet\n",
    "import pandas as pd\n",
    "import operator\n",
    "#pip install mglearn\n",
    "import mglearn\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.decomposition import PCA\n",
    "from IMDBAPI import IMDB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "imdb = IMDB()\n",
    "\n",
    "################ <Functions> ################# \n",
    "def plotcounts (a):\n",
    "    temp=a\n",
    "    temp.replace(\".\", \" \").replace(\",\", \"\")\n",
    "    temp=temp.split(\" \")\n",
    "    temp=map(lambda x:x.lower(),temp)\n",
    "    words=[]\n",
    "    for b in movie_words:\n",
    "        if b in temp:\n",
    "            words.append(b)\n",
    "    return words\n",
    "\n",
    "def worddummy (a):\n",
    "    if m in a:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def countactors(a):\n",
    "    temp.append(a.split(\", \"))\n",
    "    return temp\n",
    "\n",
    "def token(text):\n",
    "    return(text.split(\"|\"))\n",
    "\n",
    "################ <IMDB films extractor> #################\n",
    "URL = \"http://www.imdb.com/chart/top\"\n",
    "r = requests.get(URL)\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "entries=soup.findAll('div', class_=\"wlb_ribbon\")\n",
    "# getting top movies ids from imdb\n",
    "movie_ids = []\n",
    "for a in entries:\n",
    "    movie_ids.append(a['data-tconst'])\n",
    "#print(\"========= movie_ids:\", movie_ids) \n",
    "         \n",
    "header = 'http://www.omdbapi.com/?apikey=6be019fc&tomatoes=true&i='\n",
    "movie_info = []\n",
    "for i in movie_ids:\n",
    "    url = header + i\n",
    "#print(\"========= url:\", url) \n",
    "    r = requests.get(url).json()\n",
    "    movie = []\n",
    "    for a in r.keys():\n",
    "        movie.append(r[a])\n",
    "    movie_info.append(movie)\n",
    "columns = r.keys()\n",
    "df = pd.DataFrame(movie_info, columns = columns)\n",
    "#print(\"========= df:\", df)\n",
    "\n",
    "################ <Extrating from films plot the most valuable words> #################\n",
    "plots = list(df['Plot'])\n",
    "temp = \"\"\n",
    "for p in plots:\n",
    "        temp = temp + p\n",
    "temp.replace(\".\", \" \").replace(\",\", \"\")\n",
    "temp = temp.split(\" \")\n",
    "temp = list(map(lambda x:x.lower(),temp))\n",
    "#print(\"=== plot_temp:\", temp)\n",
    "\n",
    "# collect valuable for further groups generatig words\n",
    "vect = CountVectorizer(max_features=10000, max_df=.15, stop_words=\"english\").fit(temp)\n",
    "X = vect.transform(temp)\n",
    "\n",
    "# test result\n",
    "feature_names = vect.get_feature_names()\n",
    "# print(\"=== Number of features: {}\".format(len(feature_names)))\n",
    "# print(\"=== The first 20 features:\\n{}\".format(feature_names[:20]))\n",
    "# print(\"=== Each 2000 feature:\\n{}\".format(feature_names[::2000]))\n",
    "\n",
    "# Max and min groups number (if number is greater than MAX_GROUPS_NUMBER - groups won`t be dense, info become useless)\n",
    "# Here is LDA (Latent Dirichlet allocation - Латентное размещение Дирихле) is used for clustering (building topic model)\n",
    "MAX_GROUPS_NUMBER = 85\n",
    "#MIN_GROUPS_NUMBER = 10\n",
    "lda = LatentDirichletAllocation(n_components=MAX_GROUPS_NUMBER, learning_method=\"batch\", max_iter=25, random_state=0)\n",
    "document_topics = lda.fit_transform(X)\n",
    "\n",
    "# Sorting of features acsending order \n",
    "sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "# Getting of features names\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "# Take some number of topics to view results\n",
    "mglearn.tools.print_topics(topics=range(20), feature_names=feature_names,\n",
    " sorting=sorting, topics_per_chunk=5, n_words=10)\n",
    "\n",
    "################ <Demo: taking films from first two groups> ################# \n",
    "# (!!!) Take into account: films duplications were removed\n",
    "# sorting by weight document of the topic number 1\n",
    "group1 = np.argsort(document_topics[:, 1])[::-1]\n",
    "films_1 = []\n",
    "\n",
    "for i in group1[:10]:\n",
    "    films_1.append(df[df['Plot'].str.contains(temp[i])].Title.unique())\n",
    "\n",
    "print(\"========= First cluster\\n\")\n",
    "for i in set(map(tuple, films_1)):\n",
    "    print(''.join(list(i)))\n",
    "    \n",
    "# sorting by weight document of the topic number 2\n",
    "group2 = np.argsort(document_topics[:, 2])[::-1]\n",
    "films_2 = []\n",
    "\n",
    "for i in group2[:10]:\n",
    "    films_2.append(df[df['Plot'].str.contains(temp[i])].Title.unique())\n",
    "\n",
    "print(\"========= Second cluster\\n\")\n",
    "for i in set(map(tuple, films_2)):\n",
    "    print('\\n'.join(list(i)))\n",
    "    \n",
    "# sorting by weight document of the topic number 3\n",
    "# group3 = np.argsort(document_topics[:, 3])[::-1]\n",
    "# films_3 = []\n",
    "\n",
    "# for i in group3[:10]:\n",
    "#     films_3.append(df[df['Plot'].str.contains(temp[i])].Title.unique())\n",
    "\n",
    "# print(\"========= Third cluster\\n\")\n",
    "# for i in set(map(tuple, films_3)):\n",
    "#     print('\\n', list(i))\n",
    "    \n",
    "# and so on ...\n",
    "# printing will be optimized in one method"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
